/**
 * Gemini NanoBananaç”»åƒç·¨é›†ã‚µãƒ¼ãƒ“ã‚¹
 * Google AI Studioã®NanoBananaæ©Ÿèƒ½ã‚’ä½¿ã£ãŸå®Ÿéš›ã®é«ªå‹ç·¨é›†
 */

const GEMINI_API_KEY = process.env.EXPO_PUBLIC_GEMINI_API_KEY || 'AIzaSyBK6w_GZ8QJJ0Wz2X5QY3LN4M9P8R7T6V';
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent';

export interface StyleBlendPayload {
  userImage: string;
  cut: string;
  color: string;
  texture: string;
  background?: string;
  gender?: string;
  promptSummary?: string;
  promptInstructions?: string;
}

export interface StyleBlendResponse {
  success?: boolean;
  fusionImage?: string;
  narrative?: string | null;
  descriptor?: {
    cut?: string;
    color?: string;
    texture?: string;
    summary?: string | null;
  };
  error?: string;
}

export interface FaceAnalysisResult {
  faceShape: 'round' | 'oval' | 'square' | 'heart' | 'long';
  confidence: number;
  recommendations: {
    cuts: string[];
    colors: string[];
    textures: string[];
    reasoning: string;
  };
}

const DEFAULT_TIMEOUT_MS = 15000;

interface RequestOptions {
  signal?: AbortSignal;
  timeoutMs?: number;
}

function linkAbortSignals(source: AbortSignal, target: AbortController) {
  if (source.aborted) {
    target.abort();
    return () => undefined;
  }

  const onAbort = () => target.abort();
  source.addEventListener('abort', onAbort);
  return () => source.removeEventListener('abort', onAbort);
}

// é¡”å‹åˆ†æAPI
export async function analyzeFaceShape(
  imageUri: string,
  { signal, timeoutMs = DEFAULT_TIMEOUT_MS }: RequestOptions = {},
): Promise<FaceAnalysisResult> {
  const controller = new AbortController();
  const detach = signal ? linkAbortSignals(signal, controller) : undefined;
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    // å®Ÿéš›ã®Gemini APIå‘¼ã³å‡ºã—ã‚’è©¦è¡Œ
    const base64Data = imageUri.replace(/^data:image\/[a-z]+;base64,/, '') || imageUri;
    
    const prompt = `ã“ã®é¡”å†™çœŸã‚’åˆ†æã—ã¦ã€é¡”å‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®5ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€ã‚‚é©åˆã™ã‚‹ã‚‚ã®ã‚’é¸æŠã—ã€ãã®é¡”å‹ã«ä¼¼åˆã†é«ªå‹ã‚’æ¨è–¦ã—ã¦ãã ã•ã„ï¼š

1. roundï¼ˆä¸¸å‹ï¼‰ - é ¬ãŒãµã£ãã‚‰ã—ã¦ã„ã¦ã€ç¸¦ã¨æ¨ªã®æ¯”ç‡ãŒã»ã¼åŒã˜
2. ovalï¼ˆåµå‹ï¼‰ - ç†æƒ³çš„ãªãƒãƒ©ãƒ³ã‚¹ã€ç¸¦ãŒæ¨ªã‚ˆã‚Šå°‘ã—é•·ã„
3. squareï¼ˆå››è§’å‹ï¼‰ - ã‚¨ãƒ©ãŒå¼µã£ã¦ã„ã¦ã€è§’ã°ã£ãŸè¼ªéƒ­
4. heartï¼ˆãƒãƒ¼ãƒˆå‹ï¼‰ - é¡ãŒåºƒãã€é¡ãŒç´°ã„é€†ä¸‰è§’å½¢
5. longï¼ˆé¢é•·ï¼‰ - ç¸¦ã«é•·ãã€é¡ã‹ã‚‰é¡ã¾ã§ã®è·é›¢ãŒé•·ã„

åˆ†æçµæœã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "faceShape": "åˆ¤å®šã—ãŸé¡”å‹",
  "confidence": 0.85,
  "recommendations": {
    "cuts": ["ä¼¼åˆã†ã‚«ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«1", "ä¼¼åˆã†ã‚«ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«2"],
    "colors": ["ä¼¼åˆã†ã‚«ãƒ©ãƒ¼1", "ä¼¼åˆã†ã‚«ãƒ©ãƒ¼2"],
    "textures": ["ä¼¼åˆã†ãƒ†ã‚¯ã‚¹ãƒãƒ£1", "ä¼¼åˆã†ãƒ†ã‚¯ã‚¹ãƒãƒ£2"],
    "reasoning": "ã“ã®é¡”å‹ã«å¯¾ã™ã‚‹æ¨è–¦ç†ç”±"
  }
}`;

    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [
            { text: prompt },
            {
              inline_data: {
                mime_type: 'image/jpeg',
                data: base64Data
              }
            }
          ]
        }]
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      throw new Error(`Face analysis failed: ${response.status}`);
    }

    const result = await response.json();
    const text = result.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!text) {
      throw new Error('No analysis result received');
    }

    // JSONã‚’æŠ½å‡º
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid analysis response format');
    }

    return JSON.parse(jsonMatch[0]);
  } catch (error) {
    if (controller.signal.aborted) {
      throw new Error('Face analysis timed out');
    }
    throw error;
  } finally {
    clearTimeout(timeoutId);
    if (detach) detach();
  }
}

// NanoBananaã‚¹ã‚¿ã‚¤ãƒ«åˆæˆAPI
export async function requestStyleBlend(
  payload: StyleBlendPayload,
  { signal, timeoutMs = DEFAULT_TIMEOUT_MS }: RequestOptions = {},
): Promise<StyleBlendResponse> {
  console.log('=== GEMINI BRIDGE DEBUG - MALE GENDER ===');
  console.log('Payload gender:', payload.gender);
  console.log('Is male request:', payload.gender === 'male');
  
  const controller = new AbortController();
  const detach = signal ? linkAbortSignals(signal, controller) : undefined;
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const base64Data = payload.userImage.split(',')[1] || payload.userImage;
    
    // èƒŒæ™¯è¨­å®šã®å‡¦ç†
    const getBackgroundInstruction = (background?: string) => {
      switch (background) {
        case 'indoor':
          return 'Change the background to a stylish indoor setting (cafe or salon). ';
        case 'outdoor':
          return 'Change the background to a beautiful outdoor setting (park or street). ';
        case 'none':
        default:
          return 'Keep the original background unchanged. ';
      }
    };

    // Gemini 2.5 Flash Imageç”¨ã®ç”»åƒç·¨é›†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ€§åˆ¥å¯¾å¿œç‰ˆï¼‰
    const genderContext = payload.gender === 'male' ? 'for a male person' : 'for a female person';
    const prompt = `Create a new image with the person's hairstyle changed to:
- Hair cut: ${payload.cut}
- Hair color: ${payload.color}
- Hair texture: ${payload.texture}
- Style this ${genderContext}

Keep the face, skin tone, expression, and clothing exactly the same.
${getBackgroundInstruction(payload.background)}Generate a realistic photo showing the new hairstyle.

IMPORTANT: This is ${payload.gender === 'male' ? 'a male styling request' : 'a female styling request'}.`;

    console.log('About to send request to Gemini API...');
    const requestBody = {
      contents: [{
        parts: [
          { text: prompt },
          {
            inline_data: {
              mime_type: 'image/jpeg',
              data: base64Data
            }
          }
        ]
      }],
      generationConfig: {
        response_modalities: ["IMAGE"],
        temperature: 0.4,
        maxOutputTokens: 8192
      }
    };
    console.log('Request body size:', JSON.stringify(requestBody).length);
    
    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
      signal: controller.signal,
    });
    
    console.log('Response received from Gemini API');

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Gemini API error response:', errorText);
      throw new Error(`Style blend failed: ${response.status} - ${errorText}`);
    }

    const result = await response.json();
    console.log('=== FULL GEMINI API RESPONSE ===');
    console.log('Response status:', response.status);
    console.log('Response headers:', Object.fromEntries(response.headers.entries()));
    console.log('Full response:', JSON.stringify(result, null, 2));
    
    // ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’è¤‡æ•°ã®æ–¹æ³•ã§æ¢ã™
    console.log('=== SEARCHING FOR IMAGE DATA ===');
    
    // æ–¹æ³•1: inline_data
    const imageData1 = result.candidates?.[0]?.content?.parts?.find(
      (part: any) => part.inline_data && part.inline_data.mime_type?.startsWith('image/')
    )?.inline_data?.data;
    console.log('Method 1 - inline_data found:', imageData1 ? 'Yes' : 'No');
    
    // æ–¹æ³•2: inlineData (camelCase)
    const imageData2 = result.candidates?.[0]?.content?.parts?.find(
      (part: any) => part.inlineData && part.inlineData.mimeType?.startsWith('image/')
    )?.inlineData?.data;
    console.log('Method 2 - inlineData found:', imageData2 ? 'Yes' : 'No');
    
    // æ–¹æ³•3: ã™ã¹ã¦ã®partsã‚’èª¿ã¹ã‚‹
    if (result.candidates?.[0]?.content?.parts) {
      console.log('All parts in response:');
      result.candidates[0].content.parts.forEach((part: any, index: number) => {
        console.log(`Part ${index}:`, Object.keys(part));
      });
    }
    
    const imageData = imageData1 || imageData2;
    console.log('Final image data found:', imageData ? 'Yes' : 'No');
    console.log('=== MALE GENDER IMAGE DATA CHECK ===');
    console.log('Gender:', payload.gender);
    console.log('Image data exists:', !!imageData);
    if (imageData) {
      console.log('Image data length:', imageData.length);
    }
    
    if (imageData && imageData.length > 100) {  // Ensure we have substantial image data
      const genderIcon = payload.gender === 'male' ? 'ğŸ’‡â€â™‚ï¸' : 'ğŸ’‡â€â™€ï¸';
      return {
        success: true,
        fusionImage: `data:image/jpeg;base64,${imageData}`,
        narrative: `${payload.cut} Ã— ${payload.color} Ã— ${payload.texture} ã®å®Œæˆï¼

âœ¨ Gemini AIãŒå®Ÿéš›ã«ãƒ˜ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¾ã—ãŸ

${genderIcon} é¡”ã®ç‰¹å¾´ã‚’ä¿ã¡ãªãŒã‚‰ã€ç¾ã—ã„æ–°ã—ã„ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™

ğŸ¯ é¸æŠã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ãŒè‡ªç„¶ã«é©ç”¨ã•ã‚Œã¾ã—ãŸ`,
        descriptor: {
          cut: payload.cut,
          color: payload.color,
          texture: payload.texture,
          summary: 'AIç·¨é›†å®Œäº†'
        }
      };
    } else {
      console.log('=== IMAGE DATA ISSUE - THROWING ERROR ===');
      console.log('Will trigger fallback mechanism in StyleBlendService');
      throw new Error('No generated image received or image data too small');
    }
  } catch (error) {
    console.error('=== GEMINI API ERROR DETAILS ===');
    console.error('Error type:', error.constructor.name);
    console.error('Error message:', error.message);
    console.error('Full error:', error);
    
    if (controller.signal.aborted) {
      throw new Error('Style blend timed out after 15 seconds');
    }
    
    // ã‚¨ãƒ©ãƒ¼ã‚’å†æŠ•ã’ã—ã¦ã€ä¸Šä½ã§å‡¦ç†ã•ã›ã‚‹
    throw error;
    return {
      success: true,
      fusionImage: payload.userImage, // å…ƒã®ç”»åƒã‚’ä½¿ç”¨
      narrative: `${payload.cut} Ã— ${payload.color} Ã— ${payload.texture} ã®ã‚¹ã‚¿ã‚¤ãƒ«ææ¡ˆ
      
âœ¨ é¸æŠã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ã®çµ„ã¿åˆã‚ã›ã§ã™

ğŸ¯ èª¿æ•´ææ¡ˆ: é¡”å‹ã«åˆã‚ã›ã¦é•·ã•ã‚„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé­…åŠ›çš„ã«ä»•ä¸ŠãŒã‚Šã¾ã™

ğŸ’« å®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸: è‡ªç„¶ã§ç¾ã—ã„ä»•ä¸ŠãŒã‚ŠãŒæœŸå¾…ã§ãã‚‹çµ„ã¿åˆã‚ã›ã§ã™`,
      descriptor: {
        cut: payload.cut,
        color: payload.color,
        texture: payload.texture,
        summary: 'ã‚¹ã‚¿ã‚¤ãƒ«ææ¡ˆå®Œäº†'
      }
    };
  } finally {
    clearTimeout(timeoutId);
    if (detach) detach();
  }
}

// NanoBananaç”»åƒç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ - Google AI Studioã®NanoBananaæ©Ÿèƒ½ã‚’æ´»ç”¨
async function generateNanoBananaStyledImage(
  originalImage: string, 
  visualDescription: string, 
  technicalInstructions: string
): Promise<string> {
  try {
    // Gemini Vision APIã‚’ä½¿ã£ã¦å®Ÿéš›ã®ç”»åƒç·¨é›†åˆ†æã‚’è¡Œã†
    const analysisRequest = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [
            { 
              text: `ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¾å®¹å¸«AIã§ã™ã€‚ã“ã®å†™çœŸã®é«ªå‹ã‚’ä»¥ä¸‹ã®æŒ‡ç¤ºã§å¤‰æ›´ã—ãŸå ´åˆã®è©³ç´°ãªå®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ï¼š

å¤‰æ›´å†…å®¹: ${visualDescription}
æŠ€è¡“æŒ‡ç¤º: ${technicalInstructions}

å®Œæˆå¾Œã®è©³ç´°ãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚é«ªã®è‰²ã€é•·ã•ã€è³ªæ„Ÿã€ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã¾ã§å…·ä½“çš„ã«ã€‚` 
            },
            {
              inline_data: {
                mime_type: 'image/jpeg',
                data: originalImage.split(',')[1] || originalImage
              }
            }
          ]
        }],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        },
      })
    });

    if (analysisRequest.ok) {
      const analysisResult = await analysisRequest.json();
      const analysisText = analysisResult.candidates?.[0]?.content?.parts?.[0]?.text;
      
      if (analysisText) {
        console.log('NanoBanana analysis completed:', analysisText);
        
        // åˆ†æçµæœã‚’ã‚‚ã¨ã«ã€å…ƒã®ç”»åƒã«åŠ¹æœã‚’åŠ ãˆã¦è¿”ã™
        // å®Ÿéš›ã®NanoBananaæ©Ÿèƒ½ã§ã¯ã€ã“ã®åˆ†æçµæœã‚’ã‚‚ã¨ã«ç”»åƒãŒç·¨é›†ã•ã‚Œã‚‹
        return await createNanoBananaProcessedImage(originalImage, analysisText);
      }
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    return await createNanoBananaProcessedImage(originalImage, visualDescription);

  } catch (error) {
    console.warn('NanoBanana processing failed:', error);
    return await createNanoBananaProcessedImage(originalImage, visualDescription);
  }
}

// NanoBananaé¢¨ã®ç”»åƒå‡¦ç†å®Ÿè£…ï¼ˆæ¨¡æ“¬ï¼‰
async function createNanoBananaProcessedImage(originalImage: string, description: string): Promise<string> {
  return new Promise((resolve) => {
    setTimeout(() => {
      // ç¾åœ¨ã¯å…ƒã®ç”»åƒã‚’ãã®ã¾ã¾è¿”ã™ãŒã€å°†æ¥çš„ã«ã¯ä»¥ä¸‹ã‚’å®Ÿè£…äºˆå®šï¼š
      // 1. Expo ImageManipulator ã‚’ä½¿ã£ãŸå®Ÿéš›ã®ç”»åƒåŠ å·¥
      // 2. é«ªã®éƒ¨åˆ†ã®è‰²èª¿å¤‰æ›´ã€å½¢çŠ¶å¤‰æ›´
      // 3. AIåˆ†æçµæœã«åŸºã¥ãè‡ªå‹•èª¿æ•´
      
      console.log('NanoBanana image processing simulated for:', description);
      
      // å…ƒã®ç”»åƒã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸç·¨é›†æ¸ˆã¿ç”»åƒã‚’è¿”ã™
      resolve(originalImage);
    }, 3000); // NanoBananaå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
  });
}