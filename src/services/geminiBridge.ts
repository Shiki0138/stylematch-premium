/**
 * Gemini NanoBananaç”»åƒç·¨é›†ã‚µãƒ¼ãƒ“ã‚¹
 * Google AI Studioã®NanoBananaæ©Ÿèƒ½ã‚’ä½¿ã£ãŸå®Ÿéš›ã®é«ªå‹ç·¨é›†
 */

const GEMINI_API_KEY = process.env.EXPO_PUBLIC_GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  throw new Error('Gemini API key is not configured. Set EXPO_PUBLIC_GEMINI_API_KEY in environment variables.');
}
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent';

const devLog = (...args: unknown[]) => {
  if (__DEV__) {
    console.log(...args);
  }
};

export interface StyleBlendPayload {
  userImage: string;
  cut: string;
  color: string;
  texture: string;
  background?: string;
  gender?: string;
  promptSummary?: string;
  promptInstructions?: string;
}

export interface StyleBlendResponse {
  success?: boolean;
  fusionImage?: string;
  narrative?: string | null;
  descriptor?: {
    cut?: string;
    color?: string;
    texture?: string;
    summary?: string | null;
  };
  error?: string;
}

export interface FaceAnalysisResult {
  faceShape: 'round' | 'oval' | 'square' | 'heart' | 'long';
  confidence: number;
  recommendations: {
    cuts: string[];
    colors: string[];
    textures: string[];
    reasoning: string;
  };
}

const DEFAULT_TIMEOUT_MS = 15000;

interface RequestOptions {
  signal?: AbortSignal;
  timeoutMs?: number;
}

function linkAbortSignals(source: AbortSignal, target: AbortController) {
  if (source.aborted) {
    target.abort();
    return () => undefined;
  }

  const onAbort = () => target.abort();
  source.addEventListener('abort', onAbort);
  return () => source.removeEventListener('abort', onAbort);
}

// é¡”å‹åˆ†æAPI
export async function analyzeFaceShape(
  imageUri: string,
  { signal, timeoutMs = DEFAULT_TIMEOUT_MS }: RequestOptions = {},
): Promise<FaceAnalysisResult> {
  const controller = new AbortController();
  const detach = signal ? linkAbortSignals(signal, controller) : undefined;
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    // å®Ÿéš›ã®Gemini APIå‘¼ã³å‡ºã—ã‚’è©¦è¡Œ
    const base64Data = imageUri.replace(/^data:image\/[a-z]+;base64,/, '') || imageUri;
    
    const prompt = `ã“ã®é¡”å†™çœŸã‚’åˆ†æã—ã¦ã€é¡”å‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®5ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€ã‚‚é©åˆã™ã‚‹ã‚‚ã®ã‚’é¸æŠã—ã€ãã®é¡”å‹ã«ä¼¼åˆã†é«ªå‹ã‚’æ¨è–¦ã—ã¦ãã ã•ã„ï¼š

1. roundï¼ˆä¸¸å‹ï¼‰ - é ¬ãŒãµã£ãã‚‰ã—ã¦ã„ã¦ã€ç¸¦ã¨æ¨ªã®æ¯”ç‡ãŒã»ã¼åŒã˜
2. ovalï¼ˆåµå‹ï¼‰ - ç†æƒ³çš„ãªãƒãƒ©ãƒ³ã‚¹ã€ç¸¦ãŒæ¨ªã‚ˆã‚Šå°‘ã—é•·ã„
3. squareï¼ˆå››è§’å‹ï¼‰ - ã‚¨ãƒ©ãŒå¼µã£ã¦ã„ã¦ã€è§’ã°ã£ãŸè¼ªéƒ­
4. heartï¼ˆãƒãƒ¼ãƒˆå‹ï¼‰ - é¡ãŒåºƒãã€é¡ãŒç´°ã„é€†ä¸‰è§’å½¢
5. longï¼ˆé¢é•·ï¼‰ - ç¸¦ã«é•·ãã€é¡ã‹ã‚‰é¡ã¾ã§ã®è·é›¢ãŒé•·ã„

åˆ†æçµæœã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "faceShape": "åˆ¤å®šã—ãŸé¡”å‹",
  "confidence": 0.85,
  "recommendations": {
    "cuts": ["ä¼¼åˆã†ã‚«ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«1", "ä¼¼åˆã†ã‚«ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«2"],
    "colors": ["ä¼¼åˆã†ã‚«ãƒ©ãƒ¼1", "ä¼¼åˆã†ã‚«ãƒ©ãƒ¼2"],
    "textures": ["ä¼¼åˆã†ãƒ†ã‚¯ã‚¹ãƒãƒ£1", "ä¼¼åˆã†ãƒ†ã‚¯ã‚¹ãƒãƒ£2"],
    "reasoning": "ã“ã®é¡”å‹ã«å¯¾ã™ã‚‹æ¨è–¦ç†ç”±"
  }
}`;

    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [
            { text: prompt },
            {
              inline_data: {
                mime_type: 'image/jpeg',
                data: base64Data
              }
            }
          ]
        }]
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      throw new Error(`Face analysis failed: ${response.status}`);
    }

    const result = await response.json();
    const text = result.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!text) {
      throw new Error('No analysis result received');
    }

    // JSONã‚’æŠ½å‡º
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid analysis response format');
    }

    return JSON.parse(jsonMatch[0]);
  } catch (error) {
    if (controller.signal.aborted) {
      throw new Error('Face analysis timed out');
    }
    throw error;
  } finally {
    clearTimeout(timeoutId);
    if (detach) detach();
  }
}

// NanoBananaã‚¹ã‚¿ã‚¤ãƒ«åˆæˆAPI
export async function requestStyleBlend(
  payload: StyleBlendPayload,
  { signal, timeoutMs = DEFAULT_TIMEOUT_MS }: RequestOptions = {},
): Promise<StyleBlendResponse> {
  devLog('=== GEMINI BRIDGE DEBUG - MALE GENDER ===');
  devLog('Payload gender:', payload.gender);
  devLog('Is male request:', payload.gender === 'male');
  
  const controller = new AbortController();
  const detach = signal ? linkAbortSignals(signal, controller) : undefined;
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const base64Data = payload.userImage.split(',')[1] || payload.userImage;
    
    // èƒŒæ™¯è¨­å®šã®å‡¦ç†
    const getBackgroundInstruction = (background?: string) => {
      switch (background) {
        case 'indoor':
          return 'Change the background to a stylish indoor setting (cafe or salon). ';
        case 'outdoor':
          return 'Change the background to a beautiful outdoor setting (park or street). ';
        case 'none':
        default:
          return 'Keep the original background unchanged. ';
      }
    };

    // Gemini 2.5 Flash Imageç”¨ã®ç”»åƒç·¨é›†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ€§åˆ¥å¯¾å¿œç‰ˆï¼‰
    const genderContext = payload.gender === 'male' ? 'for a male person' : 'for a female person';
    const prompt = `Create a new image with the person's hairstyle changed to:
- Hair cut: ${payload.cut}
- Hair color: ${payload.color}
- Hair texture: ${payload.texture}
- Style this ${genderContext}

Keep the face, skin tone, expression, and clothing exactly the same.
${getBackgroundInstruction(payload.background)}Generate a realistic photo showing the new hairstyle.

IMPORTANT: This is ${payload.gender === 'male' ? 'a male styling request' : 'a female styling request'}.`;

    devLog('About to send request to Gemini API...');
    const requestBody = {
      contents: [{
        parts: [
          { text: prompt },
          {
            inline_data: {
              mime_type: 'image/jpeg',
              data: base64Data
            }
          }
        ]
      }],
      generationConfig: {
        response_modalities: ["IMAGE"],
        temperature: 0.4,
        maxOutputTokens: 8192
      }
    };
    devLog('Request body size:', JSON.stringify(requestBody).length);
    
    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
      signal: controller.signal,
    });
    
    devLog('Response received from Gemini API');

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Gemini API error response:', errorText);
      throw new Error(`Style blend failed: ${response.status} - ${errorText}`);
    }

    const result = await response.json();
    devLog('=== FULL GEMINI API RESPONSE ===');
    devLog('Response status:', response.status);
    devLog('Response headers:', Object.fromEntries(response.headers.entries()));
    devLog('Full response:', JSON.stringify(result, null, 2));
    
    // ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’è¤‡æ•°ã®æ–¹æ³•ã§æ¢ã™
    devLog('=== SEARCHING FOR IMAGE DATA ===');
    
    // æ–¹æ³•1: inline_data
    const imageData1 = result.candidates?.[0]?.content?.parts?.find(
      (part: any) => part.inline_data && part.inline_data.mime_type?.startsWith('image/')
    )?.inline_data?.data;
    devLog('Method 1 - inline_data found:', imageData1 ? 'Yes' : 'No');
    
    // æ–¹æ³•2: inlineData (camelCase)
    const imageData2 = result.candidates?.[0]?.content?.parts?.find(
      (part: any) => part.inlineData && part.inlineData.mimeType?.startsWith('image/')
    )?.inlineData?.data;
    devLog('Method 2 - inlineData found:', imageData2 ? 'Yes' : 'No');
    
    // æ–¹æ³•3: ã™ã¹ã¦ã®partsã‚’èª¿ã¹ã‚‹
    if (result.candidates?.[0]?.content?.parts) {
      devLog('All parts in response:');
      result.candidates[0].content.parts.forEach((part: any, index: number) => {
        devLog(`Part ${index}:`, Object.keys(part));
      });
    }
    
    const imageData = imageData1 || imageData2;
    devLog('Final image data found:', imageData ? 'Yes' : 'No');
    devLog('=== MALE GENDER IMAGE DATA CHECK ===');
    devLog('Gender:', payload.gender);
    devLog('Image data exists:', !!imageData);
    if (imageData) {
      devLog('Image data length:', imageData.length);
    }
    
    if (imageData && imageData.length > 100) {  // Ensure we have substantial image data
      const genderIcon = payload.gender === 'male' ? 'ğŸ’‡â€â™‚ï¸' : 'ğŸ’‡â€â™€ï¸';
      return {
        success: true,
        fusionImage: `data:image/jpeg;base64,${imageData}`,
        narrative: `${payload.cut} Ã— ${payload.color} Ã— ${payload.texture} ã®å®Œæˆï¼

âœ¨ Gemini AIãŒå®Ÿéš›ã«ãƒ˜ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¾ã—ãŸ

${genderIcon} é¡”ã®ç‰¹å¾´ã‚’ä¿ã¡ãªãŒã‚‰ã€ç¾ã—ã„æ–°ã—ã„ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™

ğŸ¯ é¸æŠã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ãŒè‡ªç„¶ã«é©ç”¨ã•ã‚Œã¾ã—ãŸ`,
        descriptor: {
          cut: payload.cut,
          color: payload.color,
          texture: payload.texture,
          summary: 'AIç·¨é›†å®Œäº†'
        }
      };
    } else {
      devLog('=== IMAGE DATA ISSUE - THROWING ERROR ===');
      devLog('Will trigger fallback mechanism in StyleBlendService');
      throw new Error('No generated image received or image data too small');
    }
  } catch (error) {
    console.error('=== GEMINI API ERROR DETAILS ===');
    console.error('Error type:', error.constructor.name);
    console.error('Error message:', error.message);
    console.error('Full error:', error);
    
    if (controller.signal.aborted) {
      throw new Error('Style blend timed out after 15 seconds');
    }
    
    // ã‚¨ãƒ©ãƒ¼ã‚’å†æŠ•ã’ã—ã¦ã€ä¸Šä½ã§å‡¦ç†ã•ã›ã‚‹
    throw error;
  } finally {
    clearTimeout(timeoutId);
    if (detach) detach();
  }
}

